import streamlit as st
from PIL import Image
import numpy as np
import time
import matplotlib.pyplot as plt

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from src.detection.vehicle_detector import VehicleDetector
from src.detection.plate_detector import PlateDetector
from src.preprocessing.image_processor import ImageProcessor
from src.ocr.ocr_engine import OCREngine
from src.utils.visualization import visualize_vehicle_detection, visualize_plate_detection, visualize_results

st.set_page_config(page_title="OCR Debug", page_icon="ğŸš—", layout="wide")
st.title("ì°¨ëŸ‰ë²ˆí˜¸ OCR - ê°œë°œ ë””ë²„ê·¸")

# ëª¨ë¸ ì´ˆê¸°í™”
@st.cache_resource
def load_models():
    return VehicleDetector(), PlateDetector(), ImageProcessor(), OCREngine()

vehicle_detector, plate_detector, image_processor, ocr_engine = load_models()

# ì´ë¯¸ì§€ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    image_np = np.array(image)
    
    st.header("ì›ë³¸ ì´ë¯¸ì§€")
    st.image(image, width=600)
    
    total_start = time.time()
    results = []
    
    # 1ë‹¨ê³„: ì°¨ëŸ‰ ê°ì§€
    st.header("1ë‹¨ê³„: ì°¨ëŸ‰ ê°ì§€")
    vehicle_start = time.time()
    vehicle_boxes = vehicle_detector.detect(image_np)
    vehicle_time = time.time() - vehicle_start
    
    st.write(f"ê°ì§€ëœ ì°¨ëŸ‰: {len(vehicle_boxes)}ê°œ")
    st.write(f"ì²˜ë¦¬ ì‹œê°„: {vehicle_time:.3f}ì´ˆ")
    
    if vehicle_boxes:
        st.image(visualize_vehicle_detection(image_np.copy(), vehicle_boxes), width=600)
        
        # ì°¨ëŸ‰ë³„ ë²ˆí˜¸íŒ ê°ì§€
        for idx, vehicle_box in enumerate(vehicle_boxes):
            st.subheader(f"ì°¨ëŸ‰ {idx+1}")
            x1, y1, x2, y2 = vehicle_box
            vehicle_img = image_np[y1:y2, x1:x2]
            
            # ë²ˆí˜¸íŒ ê°ì§€
            plate_start = time.time()
            plate_boxes = plate_detector.detect(vehicle_img)
            plate_time = time.time() - plate_start
            
            st.write(f"ë²ˆí˜¸íŒ ê°ì§€: {len(plate_boxes)}ê°œ, ì‹œê°„: {plate_time:.3f}ì´ˆ")
            
            if plate_boxes:
                st.image(visualize_plate_detection(vehicle_img.copy(), plate_boxes), width=400)
                
                # ê° ë²ˆí˜¸íŒ ì²˜ë¦¬
                for pidx, plate_box in enumerate(plate_boxes):
                    px1, py1, px2, py2 = plate_box
                    plate_img = vehicle_img[py1:py2, px1:px2]
                    
                    st.write(f"ë²ˆí˜¸íŒ {pidx+1}")
                    
                    # í’ˆì§ˆ í‰ê°€ (1ë‹¨ê³„ ê¸°ëŠ¥)
                    quality_start = time.time()
                    try:
                        if hasattr(image_processor, 'assess_image_quality'):
                            quality_metrics, processing_level = image_processor.assess_image_quality(plate_img)
                            st.write(f"í’ˆì§ˆ ì ìˆ˜: {quality_metrics['overall_score']:.1f}/100")
                            st.write(f"ì²˜ë¦¬ ìˆ˜ì¤€: {processing_level.upper()}")
                        else:
                            processing_level = 'full'
                            quality_metrics = {'overall_score': 0}
                    except:
                        processing_level = 'full'
                        quality_metrics = {'overall_score': 0}
                    quality_time = time.time() - quality_start
                    
                    # ì „ì²˜ë¦¬
                    preprocess_start = time.time()
                    processed = image_processor.process(plate_img)
                    preprocess_time = time.time() - preprocess_start
                    
                    # OCR
                    ocr_start = time.time()
                    text, conf = ocr_engine.recognize_with_confidence(processed)
                    ocr_time = time.time() - ocr_start
                    
                    # ë‹¨ê³„ë³„ ì „ì²˜ë¦¬ ì‹œê°í™” (Matplotlib + Streamlit)
                    if st.checkbox(f"ì „ì²˜ë¦¬ ë‹¨ê³„ë³„ ì‹œê°í™” ë³´ê¸° (ë²ˆí˜¸íŒ {pidx+1})", key=f"viz_{idx}_{pidx}"):
                        steps = image_processor.visualize_steps(plate_img)
                        fig, axes = plt.subplots(1, len(steps), figsize=(3*len(steps), 3))
                        if len(steps) == 1:
                            axes = [axes]
                        for ax, (step_name, step_img) in zip(axes, steps.items()):
                            if len(step_img.shape) == 2:
                                ax.imshow(step_img, cmap='gray')
                            else:
                                ax.imshow(step_img)
                            ax.set_title(step_name)
                            ax.axis('off')
                        st.pyplot(fig)
                        plt.close(fig)
                    
                    # ê²°ê³¼ í‘œì‹œ
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.image(plate_img, caption="ì›ë³¸", width=150)
                    with col2:
                        st.image(processed, caption=f"ì²˜ë¦¬ë¨({processing_level})", width=150)
                    with col3:
                        st.write(f"í…ìŠ¤íŠ¸: **{text}**")
                        st.write(f"ì‹ ë¢°ë„: {conf:.2f}")
                        st.write(f"í’ˆì§ˆí‰ê°€: {quality_time*1000:.1f}ms")
                        st.write(f"ì „ì²˜ë¦¬: {preprocess_time*1000:.1f}ms")
                        st.write(f"OCR: {ocr_time*1000:.1f}ms")
                    
                    # ê²°ê³¼ ì €ì¥
                    results.append({
                        "vehicle_box": vehicle_box,
                        "plate_box": [vehicle_box[0]+px1, vehicle_box[1]+py1, vehicle_box[0]+px2, vehicle_box[1]+py2],
                        "plate_text": text,
                        "confidence": conf,
                        "quality_score": quality_metrics['overall_score'],
                        "processing_level": processing_level
                    })
    
    # ì°¨ëŸ‰ ê°ì§€ ì‹¤íŒ¨ ì‹œ ì§ì ‘ ë²ˆí˜¸íŒ ê°ì§€
    if len(results) == 0:
        st.header("ëŒ€ì²´: ì§ì ‘ ë²ˆí˜¸íŒ ê°ì§€")
        direct_start = time.time()
        plate_boxes = plate_detector.detect(image_np)
        direct_time = time.time() - direct_start
        
        st.write(f"ì§ì ‘ ê°ì§€: {len(plate_boxes)}ê°œ, ì‹œê°„: {direct_time:.3f}ì´ˆ")
        
        if plate_boxes:
            st.image(visualize_plate_detection(image_np.copy(), plate_boxes), width=600)
            
            for pidx, plate_box in enumerate(plate_boxes):
                px1, py1, px2, py2 = plate_box
                plate_img = image_np[py1:py2, px1:px2]
                
                st.write(f"ë²ˆí˜¸íŒ {pidx+1}")
                
                # í’ˆì§ˆ í‰ê°€
                quality_start = time.time()
                try:
                    if hasattr(image_processor, 'assess_image_quality'):
                        quality_metrics, processing_level = image_processor.assess_image_quality(plate_img)
                    else:
                        processing_level = 'full'
                        quality_metrics = {'overall_score': 0}
                except:
                    processing_level = 'full'
                    quality_metrics = {'overall_score': 0}
                quality_time = time.time() - quality_start
                
                # ì „ì²˜ë¦¬
                preprocess_start = time.time()
                processed = image_processor.process(plate_img)
                preprocess_time = time.time() - preprocess_start
                
                # OCR
                ocr_start = time.time()
                text, conf = ocr_engine.recognize_with_confidence(processed)
                ocr_time = time.time() - ocr_start
                
                # ë‹¨ê³„ë³„ ì „ì²˜ë¦¬ ì‹œê°í™” (Matplotlib + Streamlit)
                if st.checkbox(f"ì „ì²˜ë¦¬ ë‹¨ê³„ë³„ ì‹œê°í™” ë³´ê¸° (ë²ˆí˜¸íŒ {pidx+1})", key=f"viz_direct_{pidx}"):
                    steps = image_processor.visualize_steps(plate_img)
                    fig, axes = plt.subplots(1, len(steps), figsize=(3*len(steps), 3))
                    if len(steps) == 1:
                        axes = [axes]
                    for ax, (step_name, step_img) in zip(axes, steps.items()):
                        if len(step_img.shape) == 2:
                            ax.imshow(step_img, cmap='gray')
                        else:
                            ax.imshow(step_img)
                        ax.set_title(step_name)
                        ax.axis('off')
                    st.pyplot(fig)
                    plt.close(fig)
                
                # ê²°ê³¼ í‘œì‹œ
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.image(plate_img, caption="ì›ë³¸", width=150)
                with col2:
                    st.image(processed, caption=f"ì²˜ë¦¬ë¨({processing_level})", width=150)
                with col3:
                    st.write(f"í…ìŠ¤íŠ¸: **{text}**")
                    st.write(f"ì‹ ë¢°ë„: {conf:.2f}")
                    st.write(f"í’ˆì§ˆí‰ê°€: {quality_time*1000:.1f}ms")
                    st.write(f"ì „ì²˜ë¦¬: {preprocess_time*1000:.1f}ms")
                    st.write(f"OCR: {ocr_time*1000:.1f}ms")
                
                # ê²°ê³¼ ì €ì¥
                results.append({
                    "vehicle_box": None,
                    "plate_box": plate_box,
                    "plate_text": text,
                    "confidence": conf,
                    "quality_score": quality_metrics['overall_score'],
                    "processing_level": processing_level
                })
    
    # ìµœì¢… ê²°ê³¼
    total_time = time.time() - total_start
    
    st.header("ìµœì¢… ê²°ê³¼")
    st.write(f"ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.3f}ì´ˆ")
    st.write(f"ì¸ì‹ëœ ë²ˆí˜¸íŒ: {len(results)}ê°œ")
    
    if results:
        # ìµœì¢… ì‹œê°í™”
        final_image = visualize_results(image_np.copy(), results)
        st.image(final_image, width=600)
        
        # ê²°ê³¼ í…Œì´ë¸”
        st.subheader("ìƒì„¸ ê²°ê³¼")
        for idx, result in enumerate(results):
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.write(f"ë²ˆí˜¸íŒ {idx+1}")
            with col2:
                st.write(f"**{result['plate_text']}**")
            with col3:
                st.write(f"ì‹ ë¢°ë„: {result['confidence']:.2f}")
            with col4:
                st.write(f"í’ˆì§ˆ: {result['quality_score']:.1f}")
        
        # ì²˜ë¦¬ ìˆ˜ì¤€ í†µê³„ (1ë‹¨ê³„ ê¸°ëŠ¥)
        if any(r.get('processing_level') for r in results):
            processing_levels = [r['processing_level'] for r in results if r.get('processing_level')]
            level_counts = {}
            for level in processing_levels:
                level_counts[level] = level_counts.get(level, 0) + 1
            
            st.subheader("ì²˜ë¦¬ ìˆ˜ì¤€ ë¶„í¬")
            for level, count in level_counts.items():
                st.write(f"{level.upper()}: {count}ê°œ")
    else:
        st.error("ë²ˆí˜¸íŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
    # ë””ë²„ê·¸ ì •ë³´
    with st.expander("ë””ë²„ê·¸ ë°ì´í„°"):
        debug_info = {
            "ì´_ì²˜ë¦¬_ì‹œê°„": total_time,
            "ê°ì§€ëœ_ë²ˆí˜¸íŒ_ìˆ˜": len(results),
            "ê²°ê³¼": results
        }
        st.json(debug_info)
